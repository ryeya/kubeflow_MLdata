{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eqrD65A8HoLe"
      },
      "outputs": [],
      "source": [
        "import kfp\n",
        "from kfp import dsl\n",
        "from kfp.components import create_component_from_func\n",
        "# import kfp.components as components\n",
        "from typing import NamedTuple\n",
        "\n",
        "@create_component_from_func\n",
        "def data_preprocessing():\n",
        "  import numpy as np\n",
        "  import pandas as pd\n",
        "  from minio import Minio\n",
        "  import numpy as np\n",
        "  \n",
        "  print(\"getting data\")\n",
        "\n",
        "  minio_client = Minio(\n",
        "      \"100.65.11.110:9000\",\n",
        "      access_key=\"v55j711ZNMtkTxky93Zk\",\n",
        "      secret_key=\"LjUSzTpY8PQa5AdM9DSDx3nSqNXUrLoTHLnThkfq\",\n",
        "      secure=False\n",
        "  )\n",
        "  minio_bucket = \"sample\"\n",
        "  \n",
        "  minio_client.fget_object(minio_bucket,\"uci-secom.csv\",\"/tmp/uci-secom.csv\")\n",
        "  \n",
        "  data = np.load(\"/tmp/mycsv.csv\")\n",
        "  nv = pd.concat([data.isnull().sum(), 100 * data.isnull().sum()/data.shape[0]],axis=1).rename(columns={0:'Missing_Records', 1:'Percentage (%)'})\n",
        "  df_na = nv[nv.Missing_Records>0].sort_values('Missing_Records', ascending=False)\n",
        "  df_na = df_na[df_na[\"Percentage (%)\"] > 50]\n",
        "  data = data.drop(axis=1, columns=df_na.index)\n",
        "\n",
        "  data.fillna(method='ffill', inplace=True)\n",
        "  data.fillna(method='bfill', inplace=True)\n",
        "\n",
        "  uni_col_list = []\n",
        "  for column in data.columns:\n",
        "    if data[column].nunique() == 1:\n",
        "      uni_col_list.append(column)\n",
        "\n",
        "  data_pre = data.drop(axis=1, columns=uni_col_list)\n",
        "  \n",
        "  np.save(\"/tmp/data_pre.csv\",data_pre)\n",
        "  minio_client.fput_object(minio_bucket,\"data_pre\",\"/tmp/data_pre.csv\")\n",
        "\n",
        "@create_component_from_func\n",
        "def data_scaling():\n",
        "  from imblearn.over_sampling import SMOTE\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  from sklearn.preprocessing import StandardScaler\n",
        "  from sklearn.decomposition import PCA\n",
        "  from minio import Minio\n",
        "  import numpy as np\n",
        "\n",
        "  minio_client = Minio(\n",
        "      \"100.65.11.110:9000\",\n",
        "      access_key=\"minio\",\n",
        "      secret_key=\"minio123\",\n",
        "      secure=False\n",
        "  )\n",
        "  minio_bucket = \"mlpipeline\"\n",
        "  \n",
        "  minio_client.fget_object(minio_bucket,\"data_pre.csv\",\"/tmp/data_pre.csv\")\n",
        "  \n",
        "  data = np.load(\"/tmp/data_pre.csv\")\n",
        "\n",
        "  X = data.iloc[:, 1:-1]\n",
        "  y = data.iloc[:, -1]\n",
        "  X_resample, y_resample  = SMOTE(random_state=1).fit_sample(X, y.values.ravel())\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X_resample, y_resample, random_state=50)\n",
        "\n",
        "  sc= StandardScaler()\n",
        "  X_sc = sc.fit_transform(X)\n",
        "  X_train_sc = sc.fit_transform(X_train)\n",
        "  X_test_sc = sc.transform(X_test)\n",
        "\n",
        "  pca = PCA(0.85)\n",
        "  X_sc_pca = pca.fit_transform(X_sc)\n",
        "\n",
        "  X_train_pca = pca.transform(X_train_sc)\n",
        "  X_test_pca = pca.transform(X_test_sc)\n",
        "  \n",
        "  # save to numpy file, store in Minio\n",
        "  np.save(\"/tmp/X_train_pca.npy\",X_train_pca)\n",
        "  minio_client.fput_object(minio_bucket,\"X_train_pca\",\"/tmp/X_train_pca.npy\")\n",
        "\n",
        "  np.save(\"/tmp/X_test_pca.npy\",X_test_pca)\n",
        "  minio_client.fput_object(minio_bucket,\"X_test_pca\",\"/tmp/X_test_pca.npy\")\n",
        "\n",
        "  np.save(\"/tmp/y_train.npy\",y_train)\n",
        "  minio_client.fput_object(minio_bucket,\"y_train\",\"/tmp/y_train.npy\")\n",
        "\n",
        "  np.save(\"/tmp/y_test.npy\",y_test)\n",
        "  minio_client.fput_object(minio_bucket,\"y_test\",\"/tmp/y_test.npy\")\n",
        "\n",
        "@create_component_from_func\n",
        "def data_modeling_xgb():\n",
        "  from sklearn.model_selection import GridSearchCV\n",
        "  from sklearn.externals import joblib\n",
        "  from xgboost import XGBClassifier\n",
        "  from minio import Minio\n",
        "  import numpy as np  \n",
        "  \n",
        "  minio_client = Minio(\n",
        "      \"100.65.11.110:9000\",\n",
        "      access_key=\"minio\",\n",
        "      secret_key=\"minio123\",\n",
        "      secure=False)\n",
        "  \n",
        "  minio_bucket = \"mlpipeline\"\n",
        "  \n",
        "  minio_client.fget_object(minio_bucket,\"X_train_pca.npy\",\"/tmp/X_train_pca.npy\")\n",
        "  minio_client.fget_object(minio_bucket,\"y_train.npy\",\"/tmp/y_train.npy\")\n",
        "  \n",
        "  X_train_pca = np.load(\"/tmp/X_train_pca.npy\")\n",
        "  y_train = np.load(\"/tmp/y_train.npy\")\n",
        "\n",
        "  xgb= XGBClassifier(eval_metric='error')\n",
        "  params = {'max_depth':[2,4,6,8,10,12], 'random_state':[1]}\n",
        "\n",
        "  grid_xgb = GridSearchCV(xgb, param_grid=params, scoring='accuracy', cv=10)\n",
        "  grid_xgb.fit(X_train_pca, y_train)\n",
        "  \n",
        "  joblib.dump(grid_xgb, '/tmp/xgb_model.pkl') \n",
        "  \n",
        "  minio_client.fput_object(minio_bucket,\"xgb_model\",\"/tmp/xgb_model.pkl\")\n",
        "  return \"xgb\"\n",
        "\n",
        "\n",
        "@create_component_from_func\n",
        "def data_modeling_randomforest():\n",
        "  from minio import Minio\n",
        "  from sklearn.externals import joblib\n",
        "  import numpy as np  \n",
        "  \n",
        "  minio_client = Minio(\n",
        "      \"100.65.11.110:9000\",\n",
        "      access_key=\"minio\",\n",
        "      secret_key=\"minio123\",\n",
        "      secure=False)\n",
        "  \n",
        "  minio_bucket = \"mlpipeline\"\n",
        "  \n",
        "  minio_client.fget_object(minio_bucket,\"X_train_pca.npy\",\"/tmp/X_train_pca.npy\")\n",
        "  minio_client.fget_object(minio_bucket,\"y_train.npy\",\"/tmp/y_train.npy\")\n",
        "  \n",
        "  X_train_pca = np.load(\"/tmp/X_train_pca.npy\")\n",
        "  y_train = np.load(\"/tmp/y_train.npy\")\n",
        "  \n",
        "  from sklearn.ensemble import RandomForestClassifier\n",
        "  grid_rf = RandomForestClassifier(n_estimators=60)\n",
        "  grid_rf.fit(X_train_pca, y_train)\n",
        "\n",
        "  joblib.dump(grid_rf, '/tmp/rf_model.pkl') \n",
        "  \n",
        "  minio_client.fput_object(minio_bucket,\"rf_model\",\"/tmp/rf_model.pkl\")\n",
        "  return \"rf\"\n",
        "\n",
        "@create_component_from_func\n",
        "def data_modeling_svm():\n",
        "  from sklearn.model_selection import GridSearchCV\n",
        "  from sklearn.svm import SVC\n",
        "  from sklearn.externals import joblib\n",
        "  from minio import Minio\n",
        "  import numpy as np  \n",
        "  \n",
        "  minio_client = Minio(\n",
        "      \"100.65.11.110:9000\",\n",
        "      access_key=\"minio\",\n",
        "      secret_key=\"minio123\",\n",
        "      secure=False)\n",
        "  \n",
        "  minio_bucket = \"mlpipeline\"\n",
        "  \n",
        "  minio_client.fget_object(minio_bucket,\"X_train_pca.npy\",\"/tmp/X_train_pca.npy\")\n",
        "  minio_client.fget_object(minio_bucket,\"y_train.npy\",\"/tmp/y_train.npy\")\n",
        "  \n",
        "  X_train_pca = np.load(\"/tmp/X_train_pca.npy\")\n",
        "  y_train = np.load(\"/tmp/y_train.npy\")\n",
        "  \n",
        "  svc= SVC(kernel='rbf')\n",
        "  params = {'C':[0.01,0.1,1,10,100,1000], 'gamma':[0.01,0.1,1,10,100,1000]}\n",
        "\n",
        "  grid_svm = GridSearchCV(svc, param_grid=params, scoring='accuracy', cv=10)\n",
        "  grid_svm.fit(X_train_pca, y_train)\n",
        "\n",
        "  joblib.dump(grid_svm, '/tmp/svm_model.pkl') \n",
        "  \n",
        "  minio_client.fput_object(minio_bucket,\"svm_model\",\"/tmp/svm_model.pkl\")\n",
        "  return \"svm\"\n",
        "\n",
        "@create_component_from_func\n",
        "def model_evaluation(model: str) -> NamedTuple('Output', [('mlpipeline_metadata', 'Metadata'),('mlpipeline_metrics', 'Metrics')]):\n",
        "  \n",
        "  from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, recall_score, precision_score\n",
        "  from minio import Minio\n",
        "  from sklearn.externals import joblib\n",
        "  import numpy as np  \n",
        "  import pandas as pd\n",
        "  import json\n",
        "  \n",
        "  minio_client = Minio(\n",
        "      \"100.65.11.110:9000\",\n",
        "      access_key=\"minio\",\n",
        "      secret_key=\"minio123\",\n",
        "      secure=False)\n",
        "  \n",
        "  minio_bucket = \"mlpipeline\" \n",
        "  \n",
        "  model_name = model + \"_model\"\n",
        "  model_path = \"/tmp/\" + model_name + \".pkl\"\n",
        "  \n",
        "  minio_client.fget_object(minio_bucket,\"X_test_pca.npy\",\"/tmp/X_test_pca.npy\")\n",
        "  minio_client.fget_object(minio_bucket,\"y_test.npy\",\"/tmp/y_test.npy\")\n",
        "  minio_client.fget_object(minio_bucket, model_name, model_path)\n",
        "\n",
        "  y_test = np.load(\"/tmp/y_test.npy\")\n",
        "  X_test_pca = np.load(\"/tmp/X_test_pca.npy\")\n",
        "  \n",
        "  clf = joblib.load(model_path) \n",
        "  em = clf.best_estimator_\n",
        "  pred = em.predict(X_test_pca)\n",
        "\n",
        "  \n",
        "  confusionmatrix = confusion_matrix(pred, y_test)\n",
        "  model_accuracy = accuracy_score(pred, y_test)\n",
        "  f1score = f1_score(y_test, pred)\n",
        "  recallscore = recall_score(pred, y_test)\n",
        "  precisionscore = precision_score(y_test, pred)\n",
        "\n",
        "  confusionmatrix = confusionmatrix.numpy()\n",
        "  vocab = list(np.unique(y_test))\n",
        "  data = []\n",
        "  for target_index, target_row in enumerate(confusion_matrix):\n",
        "      for predicted_index, count in enumerate(target_row):\n",
        "          data.append((vocab[target_index], vocab[predicted_index], count))\n",
        "\n",
        "  df_cm = pd.DataFrame(data, columns=['target', 'predicted', 'count'])\n",
        "  cm_csv = df_cm.to_csv(header=False, index=False)\n",
        "  \n",
        "  metadata = {\n",
        "      \"outputs\": [\n",
        "          {\n",
        "              \"type\": \"confusion_matrix\",\n",
        "              \"format\": \"csv\",\n",
        "              \"schema\": [\n",
        "                  {'name': 'target', 'type': 'CATEGORY'},\n",
        "                  {'name': 'predicted', 'type': 'CATEGORY'},\n",
        "                  {'name': 'count', 'type': 'NUMBER'},\n",
        "                ],\n",
        "              \"target_col\" : \"actual\",\n",
        "              \"predicted_col\" : \"predicted\",\n",
        "              \"source\": cm_csv,\n",
        "              \"storage\": \"inline\",\n",
        "              \"labels\": [0,1,2,3,4,5,6,7,8,9]\n",
        "          }]\n",
        "  }\n",
        "    \n",
        "  metrics = {\n",
        "    'metrics': [{\n",
        "        'name': 'model_accuracy',\n",
        "        'numberValue':  float(model_accuracy),\n",
        "        'format' : \"PERCENTAGE\"\n",
        "      },{\n",
        "        'name': 'f1_score',\n",
        "        'numberValue':  float(f1score),\n",
        "        'format' : \"PERCENTAGE\"\n",
        "      },{\n",
        "        'name': 'recall_score',\n",
        "        'numberValue':  float(recallscore),\n",
        "        'format' : \"PERCENTAGE\"\n",
        "      },{\n",
        "        'name': 'precision_score',\n",
        "        'numberValue':  float(precisionscore),\n",
        "        'format' : \"PERCENTAGE\"\n",
        "      }]}\n",
        "  \n",
        "\n",
        "  from collections import namedtuple\n",
        "  output = namedtuple('output', ['mlpipeline_metadata', 'mlpipeline_metrics'])\n",
        "  return output(json.dumps(metadata), json.dumps(metrics))\n",
        "\n",
        "@create_component_from_func\n",
        "def model_version_saved():\n",
        "  \"saved model\"\n",
        "  \n",
        "@create_component_from_func\n",
        "def model_serving():\n",
        "  \"\"\"\n",
        "  Create kserve instance\n",
        "  \"\"\"\n",
        "  from kubernetes import client \n",
        "  from kserve import KServeClient\n",
        "  from kserve import constants\n",
        "  from kserve import utils\n",
        "  from kserve import V1beta1InferenceService\n",
        "  from kserve import V1beta1InferenceServiceSpec\n",
        "  from kserve import V1beta1PredictorSpec\n",
        "  from kserve import V1beta1TFServingSpec\n",
        "  from datetime import datetime\n",
        "\n",
        "  namespace = utils.get_default_target_namespace()\n",
        "\n",
        "  now = datetime.now()\n",
        "  v = now.strftime(\"%Y-%m-%d--%H-%M-%S\")\n",
        "\n",
        "  name='ml-pipline-{}'.format(v)\n",
        "  kserve_version='v1beta1'\n",
        "  api_version = constants.KSERVE_GROUP + '/' + kserve_version\n",
        "\n",
        "  isvc = V1beta1InferenceService(api_version=api_version,\n",
        "                                  kind=constants.KSERVE_KIND,\n",
        "                                  metadata=client.V1ObjectMeta(\n",
        "                                      name=name, namespace=namespace, annotations={'sidecar.istio.io/inject':'false'}),\n",
        "                                  spec=V1beta1InferenceServiceSpec(\n",
        "                                  predictor=V1beta1PredictorSpec(\n",
        "                                      service_account_name=\"jiye-minio-kserve\",\n",
        "                                      tensorflow=(V1beta1TFServingSpec(\n",
        "                                          storage_uri=\"s3://mlpipeline/models/ml-pipeline/\")))))\n",
        "\n",
        "  KServe = KServeClient()\n",
        "  KServe.create(isvc)\n",
        "  \n",
        "# comp_data_preprocessing = components.create_component_from_func(data_preprocessing,base_image=\"public.ecr.aws/j1r0q0g6/notebooks/notebook-servers/jupyter-tensorflow-full:v1.5.0\")\n",
        "# comp_data_scaling = components.create_component_from_func(data_scaling,base_image=\"public.ecr.aws/j1r0q0g6/notebooks/notebook-servers/jupyter-tensorflow-full:v1.5.0\")\n",
        "# comp_data_modeling_xgb = components.create_component_from_func(data_modeling_xgb,base_image=\"public.ecr.aws/j1r0q0g6/notebooks/notebook-servers/jupyter-tensorflow-full:v1.5.0\")\n",
        "# comp_data_modeling_randomforest = components.create_component_from_func(data_modeling_randomforest,base_image=\"public.ecr.aws/j1r0q0g6/notebooks/notebook-servers/jupyter-tensorflow-full:v1.5.0\")\n",
        "# comp_data_modeling_svm = components.create_component_from_func(data_modeling_svm,base_image=\"public.ecr.aws/j1r0q0g6/notebooks/notebook-servers/jupyter-tensorflow-full:v1.5.0\")\n",
        "# comp_model_evaluation = components.create_component_from_func(model_evaluation,base_image=\"public.ecr.aws/j1r0q0g6/notebooks/notebook-servers/jupyter-tensorflow-full:v1.5.0\")\n",
        "# comp_model_version_saved = components.create_component_from_func(model_version_saved,base_image=\"public.ecr.aws/j1r0q0g6/notebooks/notebook-servers/jupyter-tensorflow-full:v1.5.0\")\n",
        "# comp_model_serving = components.create_component_from_func(model_serving,base_image=\"public.ecr.aws/j1r0q0g6/notebooks/notebook-servers/jupyter-tensorflow-full:v1.5.0\",\n",
        "#                                                            packages_to_install=['kserve==0.8.0.1'])\n",
        "\n",
        "@dsl.pipeline(\n",
        "  name='ml-pipeline',\n",
        "  description='Semiconductor defect detection'\n",
        ")\n",
        "def ml_pipeline():\n",
        "  step1 = data_preprocessing()  \n",
        "  step2_1 = data_modeling_xgb()\n",
        "  step2_2 = step2_1.after(step1)\n",
        "  step3_1 = data_modeling_randomforest()\n",
        "  step3_2 = step3_1.after(step1)\n",
        "  step4_1 = data_modeling_randomforest()\n",
        "  step4_2 = step4_1.after(step1)\n",
        "  \n",
        "  step5 = model_evaluation\n",
        "  step5.after(step2_2)  \n",
        "  step5.after(step3_2)  \n",
        "  step5.after(step4_2)\n",
        "    \n",
        "  step6 = model_version_saved()\n",
        "  step6.after(step5)\n",
        "  \n",
        "  step7 = model_serving()\n",
        "  step7.after(step6)\n",
        "    \n",
        "\n",
        "if __name__ == '__main__':\n",
        "    client = kfp.Client()\n",
        "    kfp.compiler.Compiler().compile(ml_pipeline, 'ml_pipeline.yaml')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
